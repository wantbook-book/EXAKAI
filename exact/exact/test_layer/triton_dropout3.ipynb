{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akai/anaconda3/envs/EXACT/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import triton\n",
    "import torch\n",
    "import triton.language as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def _rand2d(\n",
    "    randval_ptr,\n",
    "    randmask_ptr,\n",
    "    stride_m, stride_n,\n",
    "    M, N,\n",
    "    p, seed,\n",
    "    UNROLL: tl.constexpr,\n",
    "    BLOCK_SIZE: tl.constexpr,\n",
    "):\n",
    "    pid = tl.program_id(0)  \n",
    "    pid_m = pid*UNROLL\n",
    "\n",
    "    offs_row = tl.arange(0, UNROLL)\n",
    "    offs_col = tl.arange(0, BLOCK_SIZE)\n",
    "    rand_offs = offs_row[:,None]*BLOCK_SIZE + offs_col[None, :]\n",
    "    randval_ptrs = randval_ptr+(pid_m+offs_row[:, None])*stride_m + offs_col[None, :]*stride_n\n",
    "    randmask_ptrs = randmask_ptr+(pid_m+offs_row[:, None])*stride_m + offs_col[None, :]*stride_n\n",
    "    mask = ((pid_m+offs_row[:, None])<M) & (offs_col[None, :]<N)\n",
    "\n",
    "    rand = tl.rand(seed+pid, rand_offs)\n",
    "    \n",
    "    tl.store(randval_ptrs, rand, mask=mask)\n",
    "    tl.store(randmask_ptrs, rand > p, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand2d(\n",
    "        M, N,\n",
    "        p, seed,\n",
    "):\n",
    "    randval = torch.zeros((M, N), dtype=torch.float32, device='cuda')\n",
    "    randmask = torch.zeros((M, N), dtype=torch.bool, device='cuda')\n",
    "    assert randval.is_cuda and randmask.is_cuda\n",
    "    BLOCK_SIZE = triton.next_power_of_2(N)\n",
    "#     BLOCK_SIZE = N\n",
    "    UNROLL = 4\n",
    "    grid = lambda meta: (triton.cdiv(M, UNROLL),)\n",
    "    _rand2d[grid](randval, randmask, \n",
    "                  randval.stride(0), randval.stride(1), \n",
    "                  M, N,\n",
    "                  p, seed, \n",
    "                  UNROLL,\n",
    "                  BLOCK_SIZE)\n",
    "    print(randval)\n",
    "    print(randmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7981, 0.0555, 0.0389,  ..., 0.0133, 0.9774, 0.8623],\n",
      "        [0.7012, 0.0307, 0.9815,  ..., 0.4536, 0.1290, 0.4373],\n",
      "        [0.4705, 0.4544, 0.1348,  ..., 0.3655, 0.1412, 0.5890],\n",
      "        ...,\n",
      "        [0.2110, 0.1895, 0.1564,  ..., 0.8951, 0.9303, 0.3100],\n",
      "        [0.2296, 0.4710, 0.4035,  ..., 0.5152, 0.1921, 0.2477],\n",
      "        [0.3409, 0.1286, 0.5049,  ..., 0.9492, 0.3556, 0.2647]],\n",
      "       device='cuda:0')\n",
      "tensor([[ True, False, False,  ..., False,  True,  True],\n",
      "        [ True, False,  True,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True, False],\n",
      "        [False, False, False,  ...,  True, False, False],\n",
      "        [False, False,  True,  ...,  True, False, False]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "rand2d(M=2000, N=8024, p=0.5, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def _dropout(\n",
    "    input_ptr,\n",
    "    output_ptr,\n",
    "    drop_mask_ptr,\n",
    "    stride_m, stride_n,\n",
    "    # drop_mask_group_size: tl.constexpr,\n",
    "    M: tl.constexpr, N: tl.constexpr,\n",
    "    p: tl.constexpr, seed: tl.constexpr,\n",
    "    UNROLL: tl.constexpr,\n",
    "    BLOCK_SIZE: tl.constexpr,\n",
    "    drop_mask_group_size: tl.constexpr\n",
    "):\n",
    "    pid = tl.program_id(0)  \n",
    "    pid_m = pid*UNROLL\n",
    "\n",
    "    offs_row = tl.arange(0, UNROLL)\n",
    "    offs_col = tl.arange(0, BLOCK_SIZE)\n",
    "    \n",
    "    # block mask\n",
    "    rowscols_mask = ((pid_m+offs_row[:, None])<M) & (offs_col[None, :]<N)\n",
    "    input_ptrs = input_ptr + (pid_m+offs_row[:, None])*stride_m + offs_col[None, :]*stride_n\n",
    "    inputdata = tl.load(input_ptrs, mask=rowscols_mask)\n",
    "\n",
    "    # generate rand and decide which to drop\n",
    "    # rand_offs = offs_row[:,None]*BLOCK_SIZE + offs_col[None, :]\n",
    "    rand_offs = tl.arange(0,UNROLL)*N + tl.arange(0, N)\n",
    "    rand_mask = tl.rand(seed+pid, rand_offs)>p\n",
    "    # unsupported slice on constpr tensor\n",
    "    # rand_mask = rand_mask[:UNROLL, :N]\n",
    "    #\n",
    "    output_ptrs = output_ptr + (pid_m+offs_row[:, None])*stride_m + offs_col[None, :]*stride_n\n",
    "    output = tl.where(rand_mask, inputdata/(1-p), 0.0)\n",
    "\n",
    "    # compress the rand_mask to shared_drop_mask\n",
    "    shared_drop_mask = tl.zeros((1,drop_mask_group_size), dtype=tl.uint8)\n",
    "    \n",
    "    rand_mask = rand_mask.to(tl.uint8)\n",
    "    rand_mask = tl.ravel(rand_mask)\n",
    "    append_0_num = tl.cdiv(N*UNROLL, 8)*8-N*UNROLL\n",
    "    rand_mask = tl.cat((tl.view(rand_mask, (1, -1)), tl.zeros((1,append_0_num), dtype=tl.uint8)), dim=1) \n",
    "    rand_mask = tl.view(rand_mask, (-1, 8))\n",
    "    weights = (2**tl.arange(0,8))[None, :]\n",
    "    rand_mask = rand_mask * weights\n",
    "    rand_mask = tl.sum(rand_mask, axis=1)\n",
    "    # drop_mask_group_size = tl.cdiv(N*UNROLL, 8)\n",
    "    \n",
    "    drop_mask_ptrs = drop_mask_ptr + pid*drop_mask_group_size + tl.arange(0, drop_mask_group_size)\n",
    "\n",
    "    tl.store(drop_mask_ptrs, rand_mask)\n",
    "    tl.store(output_ptrs, output, mask=rowscols_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def _dropout(\n",
    "    input_ptr,\n",
    "    output_ptr,\n",
    "    drop_mask_ptr,\n",
    "    stride_m, stride_n,\n",
    "    # drop_mask_group_size: tl.constexpr,\n",
    "    M: tl.constexpr, N: tl.constexpr,\n",
    "    p: tl.constexpr, seed: tl.constexpr,\n",
    "    UNROLL: tl.constexpr,\n",
    "    BLOCK_SIZE: tl.constexpr,\n",
    "    drop_mask_group_size: tl.constexpr\n",
    "):\n",
    "    pid = tl.program_id(0)  \n",
    "    pid_m = pid*UNROLL\n",
    "\n",
    "    offs_row = tl.arange(0, UNROLL)\n",
    "    offs_col = tl.arange(0, BLOCK_SIZE)\n",
    "    \n",
    "    # block mask\n",
    "    rowscols_mask = ((pid_m+offs_row[:, None])<M) & (offs_col[None, :]<N)\n",
    "    input_ptrs = input_ptr + (pid_m+offs_row[:, None])*stride_m + offs_col[None, :]*stride_n\n",
    "    inputdata = tl.load(input_ptrs, mask=rowscols_mask)\n",
    "\n",
    "    # generate rand and decide which to drop\n",
    "    # rand_offs = offs_row[:,None]*BLOCK_SIZE + offs_col[None, :]\n",
    "    rand_offs = tl.arange(0,UNROLL)*N + tl.arange(0, N)\n",
    "    rand_mask = tl.rand(seed+pid, rand_offs)>p\n",
    "    # tl.device_print('mask', rand_mask.dtype)\n",
    "    rand_mask = rand_mask.to(tl.uint8)\n",
    "    # tl.device_print(rand_mask)\n",
    "    rand_mask = tl.view(rand_mask, (1,-1))\n",
    "    # unsupported slice on constpr tensor\n",
    "    # rand_mask = rand_mask[:UNROLL, :N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(\n",
    "        inputdata,\n",
    "        p, seed,\n",
    "):\n",
    "    output = torch.zeros_like(inputdata)\n",
    "    M, N = output.shape\n",
    "    UNROLL = 4\n",
    "    drop_mask_group_size = triton.cdiv(N*UNROLL, 8)\n",
    "    drop_mask = torch.zeros(triton.cdiv(M, UNROLL)*drop_mask_group_size, dtype=torch.uint8, device='cuda')\n",
    "    assert inputdata.is_cuda and output.is_cuda and drop_mask.is_cuda\n",
    "\n",
    "    BLOCK_SIZE = triton.next_power_of_2(N)\n",
    "    UNROLL = 4\n",
    "    grid = lambda meta: (triton.cdiv(M, UNROLL),)\n",
    "    _dropout[grid](\n",
    "        inputdata, output, drop_mask,\n",
    "        inputdata.stride(0), inputdata.stride(1),\n",
    "        M,N,\n",
    "        p, seed,\n",
    "        UNROLL,\n",
    "        BLOCK_SIZE,\n",
    "        drop_mask_group_size=drop_mask_group_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "CompilationError",
     "evalue": "at 31:39:    rowscols_mask = ((pid_m+offs_row[:, None])<M) & (offs_col[None, :]<N)\n    input_ptrs = input_ptr + (pid_m+offs_row[:, None])*stride_m + offs_col[None, :]*stride_n\n    inputdata = tl.load(input_ptrs, mask=rowscols_mask)\n\n    # generate rand and decide which to drop\n    # rand_offs = offs_row[:,None]*BLOCK_SIZE + offs_col[None, :]\n    rand_offs = tl.arange(0,UNROLL)*N + tl.arange(0, N)\n    rand_mask = tl.rand(seed+pid, rand_offs)>p\n    # tl.device_print('mask', rand_mask.dtype)\n    rand_mask = rand_mask.to(tl.uint8)\n    # tl.device_print(rand_mask)\n    rand_mask = tl.view(rand_mask, (1,-1))\n                                       ^\nValueError('cannot view block of different shape')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/site-packages/triton/compiler/code_generator.py:1122\u001b[0m, in \u001b[0;36mast_to_ttir\u001b[0;34m(fn, signature, specialization, constants, debug, arch)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1122\u001b[0m     generator\u001b[39m.\u001b[39;49mvisit(fn\u001b[39m.\u001b[39;49mparse())\n\u001b[1;32m   1123\u001b[0m \u001b[39mexcept\u001b[39;00m CompilationError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/site-packages/triton/compiler/code_generator.py:1015\u001b[0m, in \u001b[0;36mCodeGenerator.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     last_loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mget_loc()\n\u001b[0;32m-> 1015\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m   1016\u001b[0m \u001b[39m# Reset the location to the last one before the visit\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/ast.py:371\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    370\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 371\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/site-packages/triton/compiler/code_generator.py:293\u001b[0m, in \u001b[0;36mCodeGenerator.visit_Module\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_Module\u001b[39m(\u001b[39mself\u001b[39m, node):\n\u001b[0;32m--> 293\u001b[0m     ast\u001b[39m.\u001b[39;49mNodeVisitor\u001b[39m.\u001b[39;49mgeneric_visit(\u001b[39mself\u001b[39;49m, node)\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/ast.py:379\u001b[0m, in \u001b[0;36mNodeVisitor.generic_visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, AST):\n\u001b[0;32m--> 379\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(item)\n\u001b[1;32m    380\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, AST):\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/site-packages/triton/compiler/code_generator.py:1015\u001b[0m, in \u001b[0;36mCodeGenerator.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     last_loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mget_loc()\n\u001b[0;32m-> 1015\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m   1016\u001b[0m \u001b[39m# Reset the location to the last one before the visit\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/ast.py:371\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    370\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 371\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/site-packages/triton/compiler/code_generator.py:362\u001b[0m, in \u001b[0;36mCodeGenerator.visit_FunctionDef\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39m# visit function body\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_compound_statement(node\u001b[39m.\u001b[39;49mbody)\n\u001b[1;32m    363\u001b[0m \u001b[39m# finalize function\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/site-packages/triton/compiler/code_generator.py:288\u001b[0m, in \u001b[0;36mCodeGenerator.visit_compound_statement\u001b[0;34m(self, stmts)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mfor\u001b[39;00m stmt \u001b[39min\u001b[39;00m stmts:\n\u001b[0;32m--> 288\u001b[0m     ret_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(stmt)\n\u001b[1;32m    289\u001b[0m     \u001b[39mif\u001b[39;00m ret_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(stmt, ast\u001b[39m.\u001b[39mReturn):\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/site-packages/triton/compiler/code_generator.py:1015\u001b[0m, in \u001b[0;36mCodeGenerator.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     last_loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mget_loc()\n\u001b[0;32m-> 1015\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m   1016\u001b[0m \u001b[39m# Reset the location to the last one before the visit\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/ast.py:371\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    370\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 371\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/site-packages/triton/compiler/code_generator.py:414\u001b[0m, in \u001b[0;36mCodeGenerator.visit_Assign\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    413\u001b[0m names \u001b[39m=\u001b[39m _names[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 414\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node\u001b[39m.\u001b[39;49mvalue)\n\u001b[1;32m    415\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(names, \u001b[39mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/site-packages/triton/compiler/code_generator.py:1015\u001b[0m, in \u001b[0;36mCodeGenerator.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     last_loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mget_loc()\n\u001b[0;32m-> 1015\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[1;32m   1016\u001b[0m \u001b[39m# Reset the location to the last one before the visit\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/ast.py:371\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    370\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 371\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/site-packages/triton/compiler/code_generator.py:944\u001b[0m, in \u001b[0;36mCodeGenerator.visit_Call\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    943\u001b[0m         extra_kwargs[\u001b[39m'\u001b[39m\u001b[39m_generator\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[0;32m--> 944\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkws)\n\u001b[1;32m    945\u001b[0m \u001b[39mif\u001b[39;00m fn \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_namespace\u001b[39m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/site-packages/triton/language/core.py:30\u001b[0m, in \u001b[0;36mbuiltin.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     27\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDid you forget to add @triton.jit ? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(`_builder` argument must be provided outside of JIT functions.)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m     )\n\u001b[0;32m---> 30\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/site-packages/triton/language/core.py:910\u001b[0m, in \u001b[0;36mview\u001b[0;34m(input, shape, _builder)\u001b[0m\n\u001b[1;32m    909\u001b[0m shape \u001b[39m=\u001b[39m _shape_check_impl(shape)\n\u001b[0;32m--> 910\u001b[0m \u001b[39mreturn\u001b[39;00m semantic\u001b[39m.\u001b[39;49mview(\u001b[39minput\u001b[39;49m, shape, _builder)\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/site-packages/triton/language/semantic.py:532\u001b[0m, in \u001b[0;36mview\u001b[0;34m(input, dst_shape, builder)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mtype\u001b[39m.\u001b[39mnumel \u001b[39m!=\u001b[39m numel:\n\u001b[0;32m--> 532\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot view block of different shape\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    533\u001b[0m ret_ty \u001b[39m=\u001b[39m tl\u001b[39m.\u001b[39mblock_type(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mtype\u001b[39m.\u001b[39mscalar, dst_shape)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot view block of different shape",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mCompilationError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m M, N \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m, \u001b[39m4\u001b[39m\n\u001b[1;32m      2\u001b[0m inputdata \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand((M, N), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32, device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m dropout(inputdata, p\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m, seed\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[107], line 15\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(inputdata, p, seed)\u001b[0m\n\u001b[1;32m     13\u001b[0m UNROLL \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[1;32m     14\u001b[0m grid \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m meta: (triton\u001b[39m.\u001b[39mcdiv(M, UNROLL),)\n\u001b[0;32m---> 15\u001b[0m _dropout[grid](\n\u001b[1;32m     16\u001b[0m     inputdata, output, drop_mask,\n\u001b[1;32m     17\u001b[0m     inputdata\u001b[39m.\u001b[39;49mstride(\u001b[39m0\u001b[39;49m), inputdata\u001b[39m.\u001b[39;49mstride(\u001b[39m1\u001b[39;49m),\n\u001b[1;32m     18\u001b[0m     M,N,\n\u001b[1;32m     19\u001b[0m     p, seed,\n\u001b[1;32m     20\u001b[0m     UNROLL,\n\u001b[1;32m     21\u001b[0m     BLOCK_SIZE,\n\u001b[1;32m     22\u001b[0m     drop_mask_group_size\u001b[39m=\u001b[39;49mdrop_mask_group_size\n\u001b[1;32m     23\u001b[0m )\n",
      "File \u001b[0;32m<string>:62\u001b[0m, in \u001b[0;36m_dropout\u001b[0;34m(input_ptr, output_ptr, drop_mask_ptr, stride_m, stride_n, M, N, p, seed, UNROLL, BLOCK_SIZE, drop_mask_group_size, grid, num_warps, num_stages, extern_libs, stream, warmup, device, device_type)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/site-packages/triton/compiler/compiler.py:495\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(fn, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m path \u001b[39m=\u001b[39m metadata_group\u001b[39m.\u001b[39mget(ir_filename)\n\u001b[1;32m    494\u001b[0m \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m     next_module \u001b[39m=\u001b[39m compile_kernel(module)\n\u001b[1;32m    496\u001b[0m     \u001b[39mif\u001b[39;00m ir \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mamdgcn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    497\u001b[0m         extra_file_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m.hsaco_path\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/site-packages/triton/compiler/compiler.py:400\u001b[0m, in \u001b[0;36mcompile.<locals>.<lambda>\u001b[0;34m(src)\u001b[0m\n\u001b[1;32m    397\u001b[0m stages \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m    398\u001b[0m stages[\u001b[39m\"\u001b[39m\u001b[39mast\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (\u001b[39mlambda\u001b[39;00m path: fn, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    399\u001b[0m stages[\u001b[39m\"\u001b[39m\u001b[39mttir\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (\u001b[39mlambda\u001b[39;00m path: parse_mlir_module(path, context),\n\u001b[0;32m--> 400\u001b[0m                   \u001b[39mlambda\u001b[39;00m src: optimize_ttir(ast_to_ttir(src, signature, configs[\u001b[39m0\u001b[39;49m], constants, debug\u001b[39m=\u001b[39;49mdebug, arch\u001b[39m=\u001b[39;49march), arch))\n\u001b[1;32m    401\u001b[0m stages[\u001b[39m\"\u001b[39m\u001b[39mttgir\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (\u001b[39mlambda\u001b[39;00m path: parse_mlir_module(path, context),\n\u001b[1;32m    402\u001b[0m                    \u001b[39mlambda\u001b[39;00m src: optimize_ttgir(ttir_to_ttgir(src, num_warps), num_stages, arch))\n\u001b[1;32m    403\u001b[0m stages[\u001b[39m\"\u001b[39m\u001b[39mllir\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (\u001b[39mlambda\u001b[39;00m path: Path(path)\u001b[39m.\u001b[39mread_text(),\n\u001b[1;32m    404\u001b[0m                   \u001b[39mlambda\u001b[39;00m src: ttgir_to_llir(src, extern_libs, arch))\n",
      "File \u001b[0;32m~/anaconda3/envs/EXACT/lib/python3.8/site-packages/triton/compiler/code_generator.py:1131\u001b[0m, in \u001b[0;36mast_to_ttir\u001b[0;34m(fn, signature, specialization, constants, debug, arch)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m node \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1130\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m-> 1131\u001b[0m     \u001b[39mraise\u001b[39;00m CompilationError(fn\u001b[39m.\u001b[39msrc, node, \u001b[39mrepr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m ret \u001b[39m=\u001b[39m generator\u001b[39m.\u001b[39mmodule\n\u001b[1;32m   1133\u001b[0m \u001b[39m# module takes ownership of the context\u001b[39;00m\n",
      "\u001b[0;31mCompilationError\u001b[0m: at 31:39:    rowscols_mask = ((pid_m+offs_row[:, None])<M) & (offs_col[None, :]<N)\n    input_ptrs = input_ptr + (pid_m+offs_row[:, None])*stride_m + offs_col[None, :]*stride_n\n    inputdata = tl.load(input_ptrs, mask=rowscols_mask)\n\n    # generate rand and decide which to drop\n    # rand_offs = offs_row[:,None]*BLOCK_SIZE + offs_col[None, :]\n    rand_offs = tl.arange(0,UNROLL)*N + tl.arange(0, N)\n    rand_mask = tl.rand(seed+pid, rand_offs)>p\n    # tl.device_print('mask', rand_mask.dtype)\n    rand_mask = rand_mask.to(tl.uint8)\n    # tl.device_print(rand_mask)\n    rand_mask = tl.view(rand_mask, (1,-1))\n                                       ^\nValueError('cannot view block of different shape')"
     ]
    }
   ],
   "source": [
    "M, N = 5, 4\n",
    "inputdata = torch.rand((M, N), dtype=torch.float32, device='cuda')\n",
    "dropout(inputdata, p=0.5, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0],\n",
      "        [ 1,  3],\n",
      "        [ 2,  6],\n",
      "        [ 3,  9],\n",
      "        [ 4, 12],\n",
      "        [ 5, 15],\n",
      "        [ 6, 18],\n",
      "        [ 7, 21],\n",
      "        [ 8, 24],\n",
      "        [ 9, 27]])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([ 0,  3,  6,  9, 12, 15, 18, 21, 24, 27], dtype=torch.int8)\n",
      "tensor([ 0,  6, 12, 18, 24, 30, 36, 42, 48, 54], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "output = torch.zeros(10, dtype=torch.int8)\n",
    "dataindex = torch.cat((torch.arange(10)[:, None], (torch.arange(10)*3)[:, None]), dim=1)\n",
    "print(dataindex) \n",
    "print(dataindex[:, 0])\n",
    "output[dataindex[:, 0]] += dataindex[:, 1]\n",
    "print(output)\n",
    "output[dataindex[:, 0]] += dataindex[:, 1]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True, False,  True, False, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False, False, False,  True, False,\n",
      "         True, False, False,  True,  True,  True, False, False, False, False])\n",
      "torch.Size([40])\n",
      "tensor([  1,   2,   4,   8,  16,  32,  64, 128], dtype=torch.uint8)\n",
      "tensor([[1, 0, 1, 0, 0, 1, 0, 0],\n",
      "        [1, 1, 0, 0, 1, 1, 1, 1],\n",
      "        [1, 0, 1, 1, 1, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 1, 0, 1, 0],\n",
      "        [0, 1, 1, 1, 0, 0, 0, 0]], dtype=torch.int32)\n",
      "tensor([[  1,   0,   4,   0,   0,  32,   0,   0],\n",
      "        [  1,   2,   0,   0,  16,  32,  64, 128],\n",
      "        [  1,   0,   4,   8,  16,   0,   0, 128],\n",
      "        [  1,   0,   0,   0,  16,   0,  64,   0],\n",
      "        [  0,   2,   4,   8,   0,   0,   0,   0]], dtype=torch.int32)\n",
      "torch.Size([5, 8])\n",
      "tensor([ 37, 243, 157,  81,  14])\n"
     ]
    }
   ],
   "source": [
    "randmask = torch.rand((4,9), dtype=torch.float32)>0.5\n",
    "randmask = torch.cat((randmask.reshape(-1), torch.zeros((4*9+7)//8*8-4*9, dtype=torch.bool)))\n",
    "print(randmask)\n",
    "print(randmask.shape)\n",
    "randmask = randmask.reshape(-1, 8).int()\n",
    "weights = torch.pow(2, torch.arange(8, dtype=torch.uint8))\n",
    "print(weights)\n",
    "print(randmask.reshape(-1, 8))\n",
    "randmask = randmask.reshape(-1, 8)*weights[None, :] \n",
    "print(randmask)\n",
    "print(randmask.shape)\n",
    "randmask = torch.sum(randmask, dim=1)\n",
    "print(randmask)\n",
    "drop_mask = torch.zeros((4*9+7)//8, dtype=torch.int8)\n",
    "drop_mask = randmask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1,   2,   4,   8,  16,  32,  64, 128], dtype=torch.uint8)\n",
      "tensor([[ 37],\n",
      "        [243],\n",
      "        [157],\n",
      "        [ 81],\n",
      "        [ 14]])\n",
      "tensor([[ True, False,  True, False, False,  True, False, False],\n",
      "        [ True,  True, False, False,  True,  True,  True,  True],\n",
      "        [ True, False,  True,  True,  True, False, False,  True],\n",
      "        [ True, False, False, False,  True, False,  True, False],\n",
      "        [False,  True,  True,  True, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "bits = torch.pow(2, torch.arange(8, dtype=torch.uint8))\n",
    "print(bits) \n",
    "print(drop_mask[:, None])\n",
    "print(drop_mask[:, None]&bits>0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXACT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
